{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Converting a Keras model to ONNX\n\nIn the steps that follow, you will convert Keras model you just trained to the ONNX format. This will enable you to use this model for classification in a very broad range of environments, outside of Azure Databricks including:\n\n- Web services\n- iOS and Android mobile apps\n- Windows apps\n- IoT devices\n\nFurthermore, ONNX runtimes and libraries are also designed to maximize performance on some of the best hardware in the industry. In this lab, we will compare the Inference performance of the ONNX vs Keras models.\n\nFirst we will load the trained Keras model from file, and then convert the model to ONNX.",
      "attachments": {}
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Load the Keras Model\n\nLoad both the saved Keras model, and the associated vectorizer. We will convert the Keras model to ONNX format, however, we also need the vectorizer to transform the input data before making inferences."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(125)\n\nfrom keras.models import load_model\nfrom sklearn.externals import joblib\n\noutput_folder = './output'\nmodel_filename = 'final_model.hdf5'\n\nkeras_model = load_model(os.path.join(output_folder, model_filename))\nprint(keras_model.summary())\n\nvectorizer_name = 'vectorizer'\nvectorizer = joblib.load(os.path.join(output_folder, vectorizer_name))\nprint('{} loaded!'.format(vectorizer_name))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Convert to ONNX\n\nConvert the loaded Keras model to ONNX format, and save the ONNX model to the deployment folder."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import onnxmltools\n\ndeployment_folder = 'deploy'\nonnx_export_folder = 'onnx'\n\n# Convert the Keras model to ONNX\nonnx_model_name = 'claim_classifier.onnx'\nconverted_model = onnxmltools.convert_keras(keras_model, onnx_model_name, target_opset=7)\n\n# Save the model locally...\nonnx_model_path = os.path.join(deployment_folder, onnx_export_folder)\nos.makedirs(onnx_model_path, exist_ok=True)\nonnxmltools.utils.save_model(converted_model, os.path.join(onnx_model_path,onnx_model_name))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Make Inference using the ONNX Model\n\n- Create an ONNX runtime InferenceSession\n- Review the expected input shape to make inferences\n- Prepare test data\n- Make inferences using both the ONNX and the Keras Model on the test data"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### ONNX Runtime InferenceSession"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import onnxruntime\n# Load the ONNX model and observe the expected input shape\nonnx_session = onnxruntime.InferenceSession(\n    os.path.join(os.path.join(deployment_folder, onnx_export_folder), onnx_model_name))\ninput_name = onnx_session.get_inputs()[0].name\noutput_name = onnx_session.get_outputs()[0].name\nprint('Expected input shape: ', onnx_session.get_inputs()[0].shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Prepare test data\n\nLoad the helper code to normalize the test data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import sys\ndata_location = './data'\nsys.path.append(data_location)\nimport textanalytics as ta",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Normalize and transform the test data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "test_claim = ['I crashed my car into a pole.']\ntest_claim = ta.normalize_corpus(test_claim)\ntest_claim = vectorizer.transform(test_claim)\n\ntest_claim = test_claim.toarray().astype(np.float32)\nprint(test_claim.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Make Inferences\n\nMake inferences using both the ONNX and the Keras Model on the test data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Run an ONNX session to classify the sample.\nprint('ONNX prediction: ', onnx_session.run([output_name], {input_name : test_claim}))\n\n# Use Keras to make predictions on the same sample\nprint('Keras prediction: ', keras_model.predict(test_claim))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Compare Inference Performance: ONNX vs Keras\n\nEvaluate the performance of ONNX and Keras by running the same sample 20,000 times. Run the next three cells and compare the performance in your environment.",
      "attachments": {}
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Next we will compare the performance of ONNX vs Keras\nimport timeit\nn = 20000",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "start_time = timeit.default_timer()\nfor i in range(n):\n    keras_model.predict(test_claim)\nkeras_elapsed = timeit.default_timer() - start_time\nprint('Keras performance: ', keras_elapsed)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "start_time = timeit.default_timer()\nfor i in range(n):\n    onnx_session.run([output_name], {input_name : test_claim})\nonnx_elapsed = timeit.default_timer() - start_time\nprint('ONNX performance: ', onnx_elapsed)\nprint('ONNX is about {} times faster than Keras'.format(round(keras_elapsed/onnx_elapsed)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Deploy ONNX model to Azure Container Instance (ACI)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Create and connect to an Azure Machine Learning Workspace\n\nReview the workspace config file saved in the previous notebook."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!cat .azureml/config.json",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**Create the `Workspace` from the saved config file**"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import azureml.core\n\nprint(azureml.core.VERSION)\n\nfrom azureml.core.workspace import Workspace\n\nws = Workspace.from_config()\nprint(ws)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Register the model with Azure Machine Learning\n\nIn the following, you register the model and the vectorizer with Azure Machine Learning (which saves a copy in the cloud)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Register the model and vectorizer\nfrom azureml.core.model import Model\n\nregistered_model_name = 'claim_classifier_onnx'\nonnx_model_path = os.path.join(os.path.join(deployment_folder, onnx_export_folder), onnx_model_name)\n\nregistered_model = Model.register(model_path = onnx_model_path, # this points to a local file\n                       model_name = registered_model_name, # this is the name the model is registered with         \n                       description = \"Claims classification model.\",\n                       workspace = ws)\n\nprint(registered_model.name, registered_model.description, registered_model.version)\n\noutput_folder = './output'\nvectorizer_name = 'vectorizer'\nvectorizer_path = os.path.join(output_folder, vectorizer_name)\n\nregistered_vectorizer = Model.register(model_path = vectorizer_path, # this points to a local file\n                       model_name = vectorizer_name, # this is the name the model is registered with         \n                       description = \"Claims classification model vectorizer.\",\n                       workspace = ws)\n\nprint(registered_vectorizer.name, registered_vectorizer.description, registered_vectorizer.version)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Create the scoring web service\n\nWhen deploying models for scoring with Azure Machine Learning services, you need to define the code for a simple web service that will load your model and use it for scoring. By convention this service has two methods init which loads the model and run which scores data using the loaded model.\n\nThis scoring service code will later be deployed inside of a specially prepared Docker container."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Confirm that that the current directory is the parent directory of the deployment folder"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cwd = os.getcwd()\nif cwd.endswith(deployment_folder):\n    os.chdir('../')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**Save the scoring web service Python file in the deployment folder**\n\nNote that the scoring web service needs both the registered models: the ONNX model, and the vectorizer to make inferences."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile $deployment_folder/scoring_service.py\nimport json\nimport numpy as np\nimport os\nimport sys\nimport urllib.request\nimport nltk\nfrom sklearn.externals import joblib\nfrom azureml.core.model import Model\nimport onnxruntime\n\nonnx_model_name = 'claim_classifier_onnx'\nvectorizer_name = 'vectorizer'\n\ndef init():\n\n    global onnx_session\n    global vectorizer\n    \n    try:\n        # Takes at most a couple of minutes to download all NLTK content\n        print(\"downloading nltk.\")\n        nltk.download(\"all\")\n        \n        tempFolderName = './resources'\n        os.makedirs(tempFolderName, exist_ok=True)\n        print('Content files will be saved to {0}'.format(tempFolderName))\n        \n        base_data_url = 'https://databricksdemostore.blob.core.windows.net/data/05.03/'\n        filesToDownload = ['contractions.py', 'textanalytics.py']\n        \n        for file in filesToDownload:\n            data_url = os.path.join(base_data_url, file)\n            local_file_path = os.path.join(tempFolderName, file)\n            urllib.request.urlretrieve(data_url, local_file_path)\n            print('Downloaded file: ', file)\n        \n        print('Importing textanalytics...')\n        sys.path.append(tempFolderName)\n        import textanalytics as ta\n        print('Done importing textanalytics.')\n        \n        # Retrieve the path to the model file using the model name\n        onnx_model_path = Model.get_model_path(onnx_model_name)\n        print('onnx_model_path: ', onnx_model_path)\n        \n        vectorizer_path = Model.get_model_path(vectorizer_name)\n        print('vectorizer_path: ', vectorizer_path)\n        \n        onnx_session = onnxruntime.InferenceSession(onnx_model_path)\n        print('Onnx Inference Session Created!')\n        \n        vectorizer = joblib.load(vectorizer_path)\n        print('Vectorizer Loaded!')\n    except Exception as e:\n        print(e)\n\ndef run(raw_data):\n    try:\n        print(\"Received input: \", raw_data)\n        \n        print('Importing textanalytics...')\n        import textanalytics as ta\n        print('Done importing textanalytics.')\n        \n        print('Processing input...')\n        input_data = np.array(json.loads(raw_data))\n        input_data = ta.normalize_corpus(input_data)\n        input_data = vectorizer.transform(input_data)\n        input_data = input_data.toarray().astype(np.float32)\n        print('Done processing input.')\n        \n        # Run an ONNX session to classify the input.\n        result = onnx_session.run(None, {onnx_session.get_inputs()[0].name: input_data})[0].argmax(axis=1).item()\n        # return just the classification index (0 or 1)\n        return result\n    except Exception as e:\n        print(e)\n        error = str(e)\n        return error",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Package Model\n\nYour scoring service can have dependencies install by using a Conda environment file. Items listed in this file will be conda or pip installed within the Docker container that is created and thus be available to your scoring web service logic.\n\nBuild a container image that names the scoring service script, the runtime (python or Spark), the conda file, and the registered models.\n\nRun the following cell. This may take between 5-10 minutes to complete."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# create a Conda dependencies environment file\nprint(\"Creating conda dependencies file locally...\")\nfrom azureml.core.conda_dependencies import CondaDependencies \nconda_packages = ['numpy', 'scikit-learn']\npip_packages = ['nltk', 'azureml-sdk', 'onnxruntime']\nmycondaenv = CondaDependencies.create(conda_packages=conda_packages, pip_packages=pip_packages)\n\ncwd = os.getcwd()\nif not cwd.endswith(deployment_folder):\n    os.chdir(deployment_folder)\n    \nconda_file = 'dependencies.yml'\nwith open(conda_file, 'w') as f:\n    f.write(mycondaenv.serialize_to_string())\n\nruntime = 'python'\nexecution_script = 'scoring_service.py'\n\n# create container image configuration\nprint(\"Creating container image configuration...\")\nfrom azureml.core.image import ContainerImage\nimage_config = ContainerImage.image_configuration(execution_script = execution_script, \n                                                  runtime = runtime, conda_file = conda_file)\n\n# create the image\nimage_name = 'claim-classifier-image'\n\nfrom azureml.core import Image\nimage = Image.create(name=image_name, models=[registered_model, registered_vectorizer], \n                     image_config=image_config, workspace=ws)\n\n# wait for image creation to finish\nimage.wait_for_creation(show_output=True)\n\nos.chdir(\"..\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Deploy Model to ACI\n\nDeploy the webservice from the image created in the previous step.\n\nYou will see output similar to the following when your web service is ready: SucceededACI service creation operation finished, operation \"Succeeded\"\n\nRun the following cell. This takes around 5 minutes to complete."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.webservice import AciWebservice, Webservice\n\naci_config = AciWebservice.deploy_configuration(\n    cpu_cores = 1, \n    memory_gb = 1, \n    tags = {'name': 'Claim Classification'}, \n    description = \"Classifies a claim as home or auto.\")\n\nservice_name = \"claimclassservice\"\n\naci_service = Webservice.deploy_from_image(deployment_config=aci_config, \n                                           image=image, \n                                           name=service_name, \n                                           workspace=ws)\n\naci_service.wait_for_deployment(show_output=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Test Deployment"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Make direct calls on the service object"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import json\n\ntest_claims = ['I crashed my car into a pole.', \n               'The flood ruined my house.', \n               'I lost control of my car and fell in the river.']\n\nfor i in range(len(test_claims)):\n    result = aci_service.run(json.dumps([test_claims[i]]))\n    print('Predicted label for test claim #{} is {}'.format(i+1, result))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Make HTTP calls to test the deployed Web Service\n\nIn order to call the service from a REST client, you need to acquire the scoring URI. Take a note of printed scoring URI, you will need it in the last notebook.\n\nThe default settings used in deploying this service result in a service that does not require authentication, so the scoring URI is the only value you need to call this service."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import requests\n\nurl = aci_service.scoring_uri\nprint('ACI Service: Claim Classification scoring URI is: {}'.format(url))\nheaders = {'Content-Type':'application/json'}\n\nfor i in range(len(test_claims)):\n    response = requests.post(url, json.dumps([test_claims[i]]), headers=headers)\n    print('Predicted label for test claim #{} is {}'.format(i+1, response.text))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}